{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "PD4SuEvhuRWt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoQsr7M6sob8",
        "outputId": "7eed548f-283c-4d4a-f2c0-ff03562103c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Dataset loaded successfully.\n",
            "Dataset shape: (6328, 14)\n",
            "------------------------------\n",
            "Target variable 'recommended_crop' encoded into 16 classes.\n",
            "------------------------------\n",
            "Identified Feature Types:\n",
            "Categorical features: ['fertilizer_affordability', 'loan_access', 'soil_type', 'region', 'irrigation', 'financial_goal']\n",
            "Numerical features: ['farming_experience', 'soil_ph', 'rainfall', 'temperature', 'market_distance', 'income', 'land_size']\n",
            "------------------------------\n",
            "Splitting data into training and testing sets (80/20 split)...\n",
            "Training set size: 5062 samples\n",
            "Testing set size: 1266 samples\n",
            "------------------------------\n",
            "Training the XGBoost model... This may take a moment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:183: UserWarning: [21:21:27] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model training completed.\n",
            "------------------------------\n",
            "Evaluating the model on the test set...\n",
            "\n",
            "Model Accuracy: 0.1130 (11.30%)\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      coffee       0.00      0.00      0.00        27\n",
            "      cotton       0.14      0.20      0.17       145\n",
            "   groundnut       0.08      0.07      0.08        95\n",
            "        jute       0.26      0.14      0.18        50\n",
            "       maize       0.13      0.13      0.13        55\n",
            "     millets       0.16      0.16      0.16       122\n",
            "      pulses       0.11      0.10      0.11       125\n",
            "        rice       0.10      0.10      0.10        97\n",
            "     sorghum       0.07      0.05      0.06        41\n",
            "     soybean       0.13      0.13      0.13        86\n",
            "      spices       0.07      0.05      0.06        56\n",
            "   sugarcane       0.09      0.12      0.11       139\n",
            "         tea       0.19      0.13      0.16        52\n",
            "  vegetables       0.02      0.01      0.02        67\n",
            "  watermelon       0.00      0.00      0.00        21\n",
            "       wheat       0.09      0.10      0.10        88\n",
            "\n",
            "    accuracy                           0.11      1266\n",
            "   macro avg       0.10      0.09      0.10      1266\n",
            "weighted avg       0.11      0.11      0.11      1266\n",
            "\n",
            "------------------------------\n",
            "Saving the trained model and label encoder...\n",
            "Model saved successfully to 'crop_recommendation_model.joblib'\n",
            "Label encoder saved successfully to 'crop_label_encoder.joblib'\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def train_crop_recommendation_model():\n",
        "    \"\"\"\n",
        "    Loads the farmer dataset, preprocesses the data, trains an XGBoost classifier,\n",
        "    and evaluates its performance.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # 1. Load the Dataset\n",
        "        print(\"Loading dataset...\")\n",
        "        # Use the correct path provided by the environment for uploaded files.\n",
        "        df = pd.read_csv('/content/modelA_detailed_no_farmer_info.csv')\n",
        "        print(\"Dataset loaded successfully.\")\n",
        "        print(f\"Dataset shape: {df.shape}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # 2. Define Features (X) and Target (y)\n",
        "        X = df.drop('recommended_crop', axis=1)\n",
        "        y = df['recommended_crop']\n",
        "\n",
        "        # 3. Encode the Target Variable\n",
        "        # XGBoost requires the target variable to be integers (0, 1, 2, ...)\n",
        "        label_encoder = LabelEncoder()\n",
        "        y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "        # Store the mapping from encoded label to crop name for later use\n",
        "        crop_names = label_encoder.classes_\n",
        "        num_classes = len(crop_names)\n",
        "        print(f\"Target variable 'recommended_crop' encoded into {num_classes} classes.\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # 4. Identify Categorical and Numerical Features\n",
        "        categorical_features = X.select_dtypes(include=['object']).columns\n",
        "        numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "        print(\"Identified Feature Types:\")\n",
        "        print(f\"Categorical features: {list(categorical_features)}\")\n",
        "        print(f\"Numerical features: {list(numerical_features)}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # 5. Create a Preprocessing Pipeline for Features\n",
        "        # We use a ColumnTransformer to apply different transformations to different columns.\n",
        "        # - OneHotEncoder for categorical features to convert them into a numerical format.\n",
        "        # - 'passthrough' for numerical features to leave them as they are.\n",
        "        preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "            ],\n",
        "            remainder='passthrough'\n",
        "        )\n",
        "\n",
        "        # 6. Split Data into Training and Testing Sets\n",
        "        print(\"Splitting data into training and testing sets (80/20 split)...\")\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "        print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "        print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # 7. Define the XGBoost Model and create the full pipeline\n",
        "        # The pipeline will first preprocess the data and then feed it to the classifier.\n",
        "        model = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', xgb.XGBClassifier(\n",
        "                objective='multi:softmax',  # Objective for multi-class classification\n",
        "                num_class=num_classes,      # Specify the number of unique crops\n",
        "                eval_metric='mlogloss',     # Logarithmic loss metric for evaluation\n",
        "                use_label_encoder=False,    # Suppress deprecation warning\n",
        "                random_state=42\n",
        "            ))\n",
        "        ])\n",
        "\n",
        "        # 8. Train the Model\n",
        "        print(\"Training the XGBoost model... This may take a moment.\")\n",
        "        model.fit(X_train, y_train)\n",
        "        print(\"Model training completed.\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # 9. Evaluate the Model\n",
        "        print(\"Evaluating the model on the test set...\")\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        print(f\"\\nModel Accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
        "\n",
        "        # Display a detailed classification report\n",
        "        print(\"\\nClassification Report:\")\n",
        "        # We use the original string labels for better readability in the report\n",
        "        report = classification_report(\n",
        "            label_encoder.inverse_transform(y_test),\n",
        "            label_encoder.inverse_transform(y_pred)\n",
        "        )\n",
        "        print(report)\n",
        "\n",
        "        # 10. Save the Trained Model and Label Encoder\n",
        "        print(\"-\" * 30)\n",
        "        print(\"Saving the trained model and label encoder...\")\n",
        "        model_filename = 'crop_recommendation_model.joblib'\n",
        "        label_encoder_filename = 'crop_label_encoder.joblib'\n",
        "\n",
        "        joblib.dump(model, model_filename)\n",
        "        joblib.dump(label_encoder, label_encoder_filename)\n",
        "\n",
        "        print(f\"Model saved successfully to '{model_filename}'\")\n",
        "        print(f\"Label encoder saved successfully to '{label_encoder_filename}'\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: The file 'modelA_detailed_no_farmer_info.csv' was not found.\")\n",
        "        print(\"Please ensure the file is uploaded correctly before running the script.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train_crop_recommendation_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0zMYucDYtGYK"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}